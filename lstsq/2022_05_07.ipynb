{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022_05_07.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO6OaXXzhsKR2vW5ESff5fQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"fcDwXAr0aQ1G","executionInfo":{"status":"ok","timestamp":1652164315498,"user_tz":-540,"elapsed":555,"user":{"displayName":"이도훈","userId":"08244818386454187914"}}},"outputs":[],"source":["from numba import cuda, jit, float32\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from time import time"]},{"cell_type":"code","source":["@jit(nopython=True)\n","def inner_product(x, y):\n","    out = 0\n","    \n","    for i in range(x.size):\n","        out += x[i] * y[i]\n","\n","    return out"],"metadata":{"id":"tFHxRqxaIDO3","executionInfo":{"status":"ok","timestamp":1652164315498,"user_tz":-540,"elapsed":5,"user":{"displayName":"이도훈","userId":"08244818386454187914"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["@jit(nopython=True)\n","def inner_product_for_grad(x, y, b):\n","    out = b * (-1)\n","    \n","    for i in range(x.size):\n","        out += x[i] * y[i]\n","    \n","\n","    return out"],"metadata":{"id":"z6qDjMawRSF7","executionInfo":{"status":"ok","timestamp":1652164315499,"user_tz":-540,"elapsed":5,"user":{"displayName":"이도훈","userId":"08244818386454187914"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["@cuda.jit\n","def matrix_vector_multiplication(A, x, b, out):\n","    tx = cuda.threadIdx.x\n","    bx = cuda.blockIdx.x\n","\n","    i = bx * TPB + tx\n","\n","    if i < out.shape[0]:\n","        out[i] = inner_product_for_grad(A[i,:], x, b[i])"],"metadata":{"id":"KOqhjdzNZzPL","executionInfo":{"status":"ok","timestamp":1652164315499,"user_tz":-540,"elapsed":5,"user":{"displayName":"이도훈","userId":"08244818386454187914"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["TPB = 16\n","\n","@cuda.jit\n","def get_grad(A, x, b, out):\n","    sA = cuda.shared.array(shape=(TPB,TPB), dtype=float32)\n","    sB = cuda.shared.array(shape=(TPB), dtype=float32)\n","\n","    i = cuda.grid(1)\n","\n","    tx = cuda.threadIdx.x\n","    ty = cuda.threadIdx.y\n","\n","    if i >= out.shape[0]:\n","        ## Quit if (x) is outside of valid out boundary\n","        return\n","\n","    tmp = 0.\n","    for j in range(int(A.shape[0] / TPB)):\n","        ## Preload data into shared memory\n","        sA[tx, ty] = A.T[i, ty + j * TPB]\n","        sB[tx] = inner_product_for_grad(A[tx + j * TPB,:], x, b[tx + j * TPB])\n","\n","        ## Wait until all threads finish proloading\n","        cuda.syncthreads()\n","\n","        ## Computes partial product on the shared memory\n","        for k in range(TPB):\n","            tmp += sA[tx, k] * sB[tx]\n","\n","        ## Wait until all threads finish computing\n","        cuda.syncthreads()\n","\n","    out[i] = tmp"],"metadata":{"id":"AUzaE-gBImjX","executionInfo":{"status":"ok","timestamp":1652164315499,"user_tz":-540,"elapsed":5,"user":{"displayName":"이도훈","userId":"08244818386454187914"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["A = np.random.rand(1000,1000)\n","b = np.random.rand(1000)\n","x = np.random.rand(1000)\n","out = np.zeros((1000))"],"metadata":{"id":"gqxAX-owVnVF","executionInfo":{"status":"ok","timestamp":1652164315500,"user_tz":-540,"elapsed":6,"user":{"displayName":"이도훈","userId":"08244818386454187914"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["A_ = cuda.to_device(A)\n","b_ = cuda.to_device(b)\n","x_ = cuda.to_device(x)\n","out_ = cuda.to_device(out)"],"metadata":{"id":"BoKJ7M2CVuSU","executionInfo":{"status":"ok","timestamp":1652164316225,"user_tz":-540,"elapsed":730,"user":{"displayName":"이도훈","userId":"08244818386454187914"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["## Configure the blocks\n","threadsperblock = (TPB,TPB)\n","blockspergrid_x = int(np.ceil(A.shape[0] / threadsperblock[1]))\n","blockspergrid_y = int(np.ceil(A.shape[1] / threadsperblock[0]))\n","blockspergrid = (blockspergrid_x, blockspergrid_y)\n","get_grad[blockspergrid, threadsperblock](A_, x_, b_, out_)"],"metadata":{"id":"9KnQ0tqoV0b4","executionInfo":{"status":"ok","timestamp":1652164316670,"user_tz":-540,"elapsed":453,"user":{"displayName":"이도훈","userId":"08244818386454187914"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["## In CPU with numpy\n","%%time \n","for i in range(500):\n","    grad = A.T @ (A @ x - b)\n","## almost 14.6 ms takes to calculate "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONPbwl5WWzkB","executionInfo":{"status":"ok","timestamp":1652164315500,"user_tz":-540,"elapsed":6,"user":{"displayName":"이도훈","userId":"08244818386454187914"}},"outputId":"fef4bdce-3fae-4942-d318-0840097e2446"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 520 ms, sys: 23.5 ms, total: 543 ms\n","Wall time: 283 ms\n"]}]},{"cell_type":"code","source":["## Start the kernel\n","%%time \n","for i in range(500):\n","    get_grad[blockspergrid, threadsperblock](A_, x_, b_, out_)\n","## almost 1.25 ms takes to calculate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ouWFEKaxaX2U","executionInfo":{"status":"ok","timestamp":1652164334877,"user_tz":-540,"elapsed":533,"user":{"displayName":"이도훈","userId":"08244818386454187914"}},"outputId":"c9a8e0b4-7108-4b08-ca8e-1309b9f97ce9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 164 ms, sys: 4.06 ms, total: 168 ms\n","Wall time: 171 ms\n"]}]},{"cell_type":"code","source":["grad[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpsqHIBEK0AV","executionInfo":{"status":"ok","timestamp":1652164328492,"user_tz":-540,"elapsed":394,"user":{"displayName":"이도훈","userId":"08244818386454187914"}},"outputId":"65275290-115c-48db-9976-9cfa4f21cdbd"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([119761.04680633, 121216.75281535, 122725.00075552, 122477.03220112,\n","       125388.58226385, 126088.68376316, 123372.65253855, 121088.90936018,\n","       122421.62081622, 125534.37401711])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["out = out_.copy_to_host()\n","out[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwR5fq__K2Du","executionInfo":{"status":"ok","timestamp":1652164330473,"user_tz":-540,"elapsed":518,"user":{"displayName":"이도훈","userId":"08244818386454187914"}},"outputId":"106b61e9-6f1e-4981-a421-a9942dc74f00"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([119125.63091317, 120502.6331888 , 121845.22478592, 121861.09284684,\n","       123786.02289252, 124991.88896155, 121793.29539299, 119452.03149002,\n","       121057.25938263, 124614.84846944])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["2022_04_26.ipynb 에서 사용한 이상한... numba 사용말고 조금 더 개선된 방법(__shared memory__를 사용하는 방법)으로 gradient를 계산하는 것을 구현했습니다... 속도는 좀더 개선되었습니다...<br>\n","조금 걱정되는 것은 초반에 cuda.synchronize()로 thread들을 정렬시키는데에 시간이 꽤 오래걸려 실제 사용중에도 시간이 오래걸리는 원인이 되지 않을까 걱정됩니다... 오히려 없는것이 더 빠른 요상한 경우가 있네요...<br>\n","> @jit 데코레이터는 첫번째 컴파일시 코드를 조금 변형해 더 빠르게 만들어 주므로, 첫번째 컴파일은 굉장히(상대적으로) 오래걸립니다. 마치 C언어를 컴파일하는 느낌으로 이해하면 잘 와다았습니다.<br>\n","\n","그리고 또, 실질적으로 학습시에 CPU, GPU간 통신의 latency 로 여기서 얻은 시간 단축이 무용지물이 될 가능성도 염두해두고 있습니다...<br>\n","마지막으로 오차가 0.0361이나 되는 것이 걱정됩니다... 계산상 과정은 똑같은데 세분화되면서 오차가 누적되었나 싶기도 하네요... 오차 계산시에 1e-6을 곱해준 것은 실질적인 learning rate가 $lr = \\frac{1e-3}{A.shape[0]}$으로 계산되어서 $A.shape[0] = 1000$을 대입해준 $lr = 1e-6$입니다. 이러니 오차가 굉장히 크네요."],"metadata":{"id":"uT7o2Ja2vC9u"}}]}